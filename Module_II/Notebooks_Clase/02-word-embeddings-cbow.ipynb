{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# Modulo II: Vectores Palabra (Word Embeddings) y CBOW 02\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veremos cómo preparar los datos para aplicar:\n",
    "\n",
    "\n",
    "- Propagación hacia adelante (Forward propagation).\n",
    "\n",
    "- Pérdida de entropía cruzada (crosss-entropy loss).\n",
    "\n",
    "- Retropropagación (Backpropagation).\n",
    "\n",
    "- Descenso de gradiente (gradient descent).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"width:image width px; font-size:100%; text-align:center;\"><img src='Figures/cbow_model_dimensions_single_input.png' alt=\"alternate text\" width=\"width\" height=\"height\" style=\"width:839;height:349;\" /> Figure 2 </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3\n",
    "V = 5\n",
    "\n",
    "\n",
    "# Inicializando los pesos de la red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialización de pesos y bías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = np.array([[ 0.41687358,  0.08854191, -0.23495225,  0.28320538,  0.41800106],\n",
    "               [ 0.32735501,  0.22795148, -0.23951958,  0.4117634 , -0.23924344],\n",
    "               [ 0.26637602, -0.23846886, -0.37770863, -0.11399446,  0.34008124]])\n",
    "\n",
    "\n",
    "W2 = np.array([[-0.22182064, -0.43008631,  0.13310965],\n",
    "               [ 0.08476603,  0.08123194,  0.1772054 ],\n",
    "               [ 0.1871551 , -0.06107263, -0.1790735 ],\n",
    "               [ 0.07055222, -0.02015138,  0.36107434],\n",
    "               [ 0.33480474, -0.39423389, -0.43959196]])\n",
    "\n",
    "\n",
    "b1 = np.array([[ 0.09688219],\n",
    "               [ 0.29239497],\n",
    "               [-0.27364426]])\n",
    "\n",
    "\n",
    "b2 = np.array([[ 0.0352008 ],\n",
    "               [-0.36393384],\n",
    "               [-0.12775555],\n",
    "               [-0.34802326],\n",
    "               [-0.07017815]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregar las funciones vistas en los notebooks pasados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict(data):\n",
    "    words = sorted(list(set(data)))\n",
    "    n = len(words)\n",
    "    idx = 0\n",
    "    # return these correctly\n",
    "    word2Ind = {}\n",
    "    Ind2word = {}\n",
    "    for k in words:\n",
    "        word2Ind[k] = idx\n",
    "        Ind2word[idx] = k\n",
    "        idx += 1\n",
    "    return word2Ind, Ind2word\n",
    "\n",
    "def get_windows(words, C):\n",
    "    i = C\n",
    "    while i < len(words) - C:\n",
    "        center_word = words[i]\n",
    "        context_words = words[(i - C):i] + words[(i+1):(i+C+1)]\n",
    "        yield context_words, center_word\n",
    "        i += 1\n",
    "\n",
    "def word_to_one_hot_vector(word, word2Ind, V):\n",
    "    one_hot_vector = np.zeros(V)\n",
    "    one_hot_vector[word2Ind[word]] = 1\n",
    "    return one_hot_vector\n",
    "\n",
    "def context_words_to_vector(context_words, word2Ind, V):\n",
    "    context_words_vectors = [word_to_one_hot_vector(w, word2Ind, V) for w in context_words]\n",
    "    context_words_vectors = np.mean(context_words_vectors, axis=0)\n",
    "    return context_words_vectors\n",
    "\n",
    "def get_training_example(words, C, word2Ind, V):\n",
    "    for context_words, center_word in get_windows(words, C):\n",
    "        yield context_words_to_vector(context_words, word2Ind, V), word_to_one_hot_vector(center_word, word2Ind, V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['i', 'am', 'happy', 'because', 'i', 'am', 'learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word2Ind, Ind2word = get_dict(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'am', 1: 'because', 2: 'happy', 3: 'i', 4: 'learning'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'because': 1, 'happy': 2, 'i': 3, 'learning': 4}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Ind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_examples = get_training_example(words, 2, word2Ind, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_training_example at 0x7fc9f562b9e0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_array, y_array = next(training_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25, 0.25, 0.  , 0.5 , 0.  ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x_array.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25],\n",
       "       [0.25],\n",
       "       [0.  ],\n",
       "       [0.5 ],\n",
       "       [0.  ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(V,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25],\n",
       "       [0.25],\n",
       "       [0.  ],\n",
       "       [0.5 ],\n",
       "       [0.  ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape=(V,1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_array.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape = (V,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    result = z.copy()\n",
    "    result[result<0]=0\n",
    "    return result\n",
    "\n",
    "def softmax(z):\n",
    "    e_z= np.exp(z)\n",
    "    sum_ez = np.sum(e_z)\n",
    "    return e_z / sum_ez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores de la capa oculta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbf{z_1} = \\mathbf{W_1}\\mathbf{x} + \\mathbf{b1} \\\\\n",
    "\\mathbf{h} = \\mathbf{ReLu}(\\mathbf{z_1)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = np.dot(W1, x) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36483875],\n",
       "       [ 0.63710329],\n",
       "       [-0.3236647 ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36483875],\n",
       "       [0.63710329],\n",
       "       [0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h = relu(z1)\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valores de la capa de salida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mathbf{z_2} = \\mathbf{W_2}\\mathbf{h} + \\mathbf{b2} \\\\\n",
    "\\mathbf{\\hat{y}} = \\mathbf{softmax}(\\mathbf{z_2)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "z2 = np.dot(W2, h) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = softmax(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18519074],\n",
       "       [0.19245626],\n",
       "       [0.23107446],\n",
       "       [0.18236353],\n",
       "       [0.20891502]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'happy'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ind2word[y_hat.argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ J = -\\sum\\limits_{k=1}^{V} y_k \\log{\\hat{y}_k}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(y_predicted, y_actual):\n",
    "    loss = np.sum(-np.log(y_predicted)*y_actual)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4650152923611106"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las formulas que necesitamos para implementar el backpropagation son:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    " \\frac{\\partial J}{\\partial \\mathbf{W_1}} &= \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right )\\mathbf{x}^\\top \\tag{7}\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{W_2}} &= (\\mathbf{\\hat{y}} - \\mathbf{y})\\mathbf{h^\\top} \\tag{8}\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{b_1}} &= \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right ) \\tag{9}\\\\\n",
    " \\frac{\\partial J}{\\partial \\mathbf{b_2}} &= \\mathbf{\\hat{y}} - \\mathbf{y} \\tag{10}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcule la derivada parcial de la función de pérdida con respecto a $ \\mathbf {b_2} $ y almacene el resultado en `grad_b2`.\n",
    "\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{b_2}} = \\mathbf{\\hat{y}} - \\mathbf{y} \\tag{10}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_b2 = y_hat - y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.18519074],\n",
       "       [ 0.19245626],\n",
       "       [-0.76892554],\n",
       "       [ 0.18236353],\n",
       "       [ 0.20891502]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_b2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular la derivada parcial de la función con respecto a $ \\mathbf {w_2} $, y guardarlo en `grad_W2`\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{W_2}} = (\\mathbf{\\hat{y}} - \\mathbf{y})\\mathbf{h^\\top} \\tag{8}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06756476,  0.11798563,  0.        ],\n",
       "       [ 0.0702155 ,  0.12261452,  0.        ],\n",
       "       [-0.28053384, -0.48988499, -0.        ],\n",
       "       [ 0.06653328,  0.1161844 ,  0.        ],\n",
       "       [ 0.07622029,  0.13310045,  0.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_w2 = np.dot((y_hat - y), h.T)\n",
    "grad_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora, calcule la derivada con respecto a $\\mathbf{b_1}$ y guardar el resultado en `grad_b1`.**\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{b_1}} = \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right ) \\tag{9}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.17045858]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_b1 = relu(np.dot(W2.T, (y_hat - y)))\n",
    "grad_b1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finalmente, calcular la derivada parcial del loss con respecto a $\\mathbf{W_1}$, y guardarlo en`grad_W1`.**\n",
    "\n",
    "$$\\frac{\\partial J}{\\partial \\mathbf{W_1}} = \\rm{ReLU}\\left ( \\mathbf{W_2^\\top} (\\mathbf{\\hat{y}} - \\mathbf{y})\\right )\\mathbf{x}^\\top \\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.04261464, 0.04261464, 0.        , 0.08522929, 0.        ]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_w1 = np.dot(relu(np.dot(W2.T,grab_b2)),x.T)\n",
    "grad_w1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado esperado\n",
    "\n",
    "    array([[0.        , 0.        , 0.        , 0.        , 0.        ],\n",
    "           [0.        , 0.        , 0.        , 0.        , 0.        ],\n",
    "           [0.04261464, 0.04261464, 0.        , 0.08522929, 0.        ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiante descendente\n",
    "\n",
    "Durante la fase del gradiante descendente, actualizará los pesos y los bías $ \\alpha $ veces el gradiente de las matrices y vectores originales, utilizando las siguientes fórmulas.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{W_1} &:= \\mathbf{W_1} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W_1}} \\tag{11}\\\\\n",
    " \\mathbf{W_2} &:= \\mathbf{W_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W_2}} \\tag{12}\\\\\n",
    " \\mathbf{b_1} &:= \\mathbf{b_1} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_1}} \\tag{13}\\\\\n",
    " \\mathbf{b_2} &:= \\mathbf{b_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_2}} \\tag{14}\\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora Calcule los nuevo valores de $\\mathbf{W_2}$ (que serán guardados en `W2_new`), $\\mathbf{b_1}$ (en `b1_new`), y $\\mathbf{b_2}$ (en `b2_new`).**\n",
    "\n",
    "\\begin{align}\n",
    " \\mathbf{W_2} &:= \\mathbf{W_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{W_2}} \\tag{12}\\\\\n",
    " \\mathbf{b_1} &:= \\mathbf{b_1} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_1}} \\tag{13}\\\\\n",
    " \\mathbf{b_2} &:= \\mathbf{b_2} - \\alpha \\frac{\\partial J}{\\partial \\mathbf{b_2}} \\tag{14}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actualizacion de pesos\n",
    "w1_new = W1 - alpha*grad_w1\n",
    "w2_new = W2 - alpha*grad_w2\n",
    "b1_new = b1 - alpha*grad_b1\n",
    "b2_new = b2 - alpha*grad_b2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41687358,  0.08854191, -0.23495225,  0.28320538,  0.41800106],\n",
       "       [ 0.32735501,  0.22795148, -0.23951958,  0.4117634 , -0.23924344],\n",
       "       [ 0.26637602, -0.23846886, -0.37770863, -0.11399446,  0.34008124]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41687358,  0.08854191, -0.23495225,  0.28320538,  0.41800106],\n",
       "       [ 0.32735501,  0.22795148, -0.23951958,  0.4117634 , -0.23924344],\n",
       "       [ 0.25359163, -0.25125325, -0.37770863, -0.13956325,  0.34008124]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opción 1: extraer los embeddings de W1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.41687358,  0.08854191, -0.23495225,  0.28320538,  0.41800106],\n",
       "       [ 0.32735501,  0.22795148, -0.23951958,  0.4117634 , -0.23924344],\n",
       "       [ 0.25359163, -0.25125325, -0.37770863, -0.13956325,  0.34008124]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am\n",
      "because\n",
      "happy\n",
      "i\n",
      "learning\n"
     ]
    }
   ],
   "source": [
    "for i in range(V):\n",
    "    print(Ind2word[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': 0, 'because': 1, 'happy': 2, 'i': 3, 'learning': 4}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{x} ----> {w1_new[]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opción 2: extraer los embeddings de W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.24209007, -0.465482  ,  0.13310965],\n",
       "       [ 0.06370138,  0.04444758,  0.1772054 ],\n",
       "       [ 0.27131525,  0.08589287, -0.1790735 ],\n",
       "       [ 0.05059224, -0.0550067 ,  0.36107434],\n",
       "       [ 0.31193865, -0.43416402, -0.43959196]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opción 3: extraer los embeddings de W1 y W2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W3 = (W1 + W2)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(xtrain,ytrain, N, V, numiter, alpha):\n",
    "    \n",
    "    #inicicalizar el modelo\n",
    "    W1,W2,b1,b2\n",
    "    \n",
    "    for i in range(numiter):\n",
    "        \n",
    "        z,h,yhat = forward(xtrain,ytrain,w1,w2,b1,b2)\n",
    "        \n",
    "        cost = funcion_costo(ytrain, yhat)\n",
    "        \n",
    "        grad_w1,grad_w2 ... = back_prop\n",
    "        \n",
    "        # actualizar los pesos\n",
    "        W1 = W1 - alpha*grad_w1\n",
    "        W2 = W2 - alpha*grad_w2\n",
    "        b1 = b1 - alpha*grad_b1\n",
    "        b2 = b2 - alpha*grad_b2\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
