{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# Modulo II: Manipulación de Vectores Palabra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos wordembeddings previamente entrenada para encontrar analogías y equivalencias de palabras. Aplicaremos operaciones de álgebra lineal usando `NumPy` para encontrar analogías entre palabras manualmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que el modelo está cargado, podemos echar un vistazo a las representaciones de palabras. Primero, tenga en cuenta que _word_embeddings_ es un diccionario. Cada palabra es la clave de la entrada y el valor es su correspondiente presentación vectorial. Recuerde que los corchetes permiten el acceso a cualquier entrada si existe la clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es importante tener en cuenta que almacenamos cada vector como una matriz NumPy. Nos permite usar las operaciones de álgebra lineal sobre él.\n",
    "\n",
    "Los vectores tienen un tamaño de 300, mientras que el tamaño del vocabulario de Google News es de alrededor de 3 millones de palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operando con word embeddings\n",
    "\n",
    "Recuerde que comprender los datos es uno de los pasos más críticos en la ciencia de datos. Los wordembeddings son el resultado de procesos de aprendizaje automático y serán parte de la entrada para procesos posteriores. Los wordembeddings deben validarse o al menos comprenderse porque el rendimiento del modelo derivado dependerá en gran medida de su calidad.\n",
    "\n",
    "Los wordembeddings son matrices multidimensionales, generalmente con cientos de atributos que suponen un desafío para su interpretación.\n",
    "\n",
    "A continuación utilizaremos algunos wordembeddings y un par de sus atributos para visualización.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenga en cuenta que palabras similares como 'village' y 'town' o 'petroleum', 'petróleo' y 'gas' tienden a apuntar en la misma dirección. Además, tenga en cuenta que \"sad\" y \"happy\" se ven juntos; sin embargo, los vectores apuntan en direcciones opuestas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia  entre las palabras\n",
    "\n",
    "Ploteando las palabras 'sad', 'happy', 'town', and 'village'. En este mismo gráfico, mostraremos el vector de 'village' a 'city' y el vector de 'sad' a 'happy'. Usemos NumPy para estas operaciones de álgebra lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algebra Lineal con word embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting capitals\n",
    "\n",
    "Now, applying vector difference and addition, one can create a vector representation for a new word. For example, we can say that the vector difference between 'France' and 'Paris' represents the concept of Capital.\n",
    "\n",
    "One can move from the city of Madrid in the direction of the concept of Capital, and obtain something close to the corresponding country to which Madrid is the Capital.\n",
    "\n",
    "Ahora, aplicando la diferencia y la suma de vectores, se puede crear una representación vectorial para una nueva palabra. Por ejemplo, podemos decir que la diferencia vectorial entre 'Francia' y 'París' representa el concepto de Capital.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno puede moverse desde la ciudad de Madrid en la dirección del concepto de Capital, y obtener algo cercano al país correspondiente al que Madrid es la Capital."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the vector 'country' that we expected to be the same as the vector for Spain is not exactly it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Entonces, tenemos que buscar las palabras más cercanas en los vectores que coincidan con el país candidato. La palabra más similar debe ser 'España'. Definamos una función que nos ayude a hacerlo. Almacenaremos nuestra incrustación de palabras como un DataFrame, que facilitará las operaciones de búsqueda basadas en los vectores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora busquemos el nombre que corresponde al país"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting other Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representa una oración como un vector\n",
    "\n",
    "Una oración completa se puede representar como un vector sumando todos los vectores de palabras que se ajustan a la oración. Dejanos ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
