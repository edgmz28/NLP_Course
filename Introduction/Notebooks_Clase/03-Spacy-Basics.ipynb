{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# Introducción: Librería spaCy\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**spaCy** (https://spacy.io/) es una biblioteca de Python de código abierto que analiza y \"comprende\" grandes volúmenes de texto. Hay disponibles modelos separados que se adaptan a idiomas específicos (inglés, francés, alemán, etc.).\n",
    "\n",
    "En esta sección instalaremos y configuraremos spaCy para que funcione con Python y luego presentaremos algunos conceptos relacionados con el procesamiento del lenguaje natural."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instalación\n",
    "\n",
    "La instalación es un proceso de dos pasos. Primero, instale spaCy usando conda o pip. A continuación, descargue el modelo específico que desee, según el idioma. <br> Para obtener más información, visite https://spacy.io/usage/\n",
    "\n",
    "### 1. Desde la  terminal:\n",
    "> `conda install -c conda-forge spacy`\n",
    "> <br>*or*<br>\n",
    "> `pip install -U spacy`\n",
    "\n",
    "> ### Podemos crear un ambiente virtual:\n",
    "> `conda create -n spacyenv python=3 spacy=2`\n",
    "\n",
    "### 2. A continuación, también desde la línea de comandos (debe ejecutar esto como administrador o usar sudo):\n",
    "\n",
    "> `python -m spacy download en`\n",
    "\n",
    "> ### Si tiene éxito, debería ver un mensaje como:\n",
    "\n",
    "> **`Linking successful`**<br>\n",
    "> `    C:\\Anaconda3\\envs\\spacyenv\\lib\\site-packages\\en_core_web_sm -->`<br>\n",
    "> `    C:\\Anaconda3\\envs\\spacyenv\\lib\\site-packages\\spacy\\data\\en`<br>\n",
    "> ` `<br>\n",
    "> `    You can now load the model via spacy.load('en')`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajando con spaCy en Python\n",
    "\n",
    "Este es un conjunto típico de instrucciones para importar y trabajar con spaCy. No se sorprenda si esto toma un tiempo, spaCy tiene una biblioteca bastante grande para cargar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto no parece muy fácil de usar, pero de inmediato vemos que suceden algunas cosas interesantes:\n",
    "1. Se reconoce que Tesla es un sustantivo propio, no solo una palabra al comienzo de una oración.\n",
    "2. EE. UU. Se mantiene unido como una entidad (a esto lo llamamos un \"token\")\n",
    "\n",
    "A medida que nos sumerjamos más en el espacio, veremos qué significan cada una de estas abreviaturas y cómo se derivan. También veremos cómo spaCy puede interpretar los últimos tres tokens combinados de \"$ 6 millones\" como una referencia a ***dinero***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Objetos spaCy\n",
    "\n",
    "Después de importar el módulo de espacio en la celda de arriba, cargamos un ** modelo ** y lo llamamos `nlp`. <br> A continuación, creamos un objeto ** Doc ** aplicando el modelo a nuestro texto y lo llamamos` doc `. <br> spaCy también crea un objeto ** Vocab ** complementario que cubriremos en secciones posteriores. <br> El objeto ** Doc ** que contiene el texto procesado es nuestro enfoque aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Pipeline\n",
    "Cuando ejecutamos `nlp`, nuestro texto entra en una * canalización de procesamiento * que primero desglosa el texto y luego realiza una serie de operaciones para etiquetar, analizar y describir los datos. Fuente de imagen:\n",
    "https://spacy.io/usage/spacy-101#pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='Figures/pipeline1.png' width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos comprobar qué componentes están actualmente en proceso. En secciones posteriores, aprenderemos cómo deshabilitar componentes y agregar nuevos según sea necesario. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Tokenización\n",
    "El primer paso en el procesamiento del texto es dividir todos los componentes (palabras y puntuación) en \"fichas\". Estos tokens están anotados dentro del objeto Doc para contener información descriptiva. Entraremos en muchos más detalles sobre la tokenización en una próxima conferencia. Por ahora, veamos otro ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe cómo \"no\" se ha dividido en dos fichas. spaCy reconoce tanto la raíz del verbo \"es\" como la negación que se le atribuye. Observe también que tanto el espacio en blanco extendido como el punto al final de la oración tienen asignados sus propios tokens.\n",
    "\n",
    "Es importante tener en cuenta que aunque `doc2` contiene información procesada sobre cada token, también conserva el texto original:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Etiquetado de parte del discurso (POS)\n",
    "El siguiente paso después de dividir el texto en fichas es asignar partes del discurso. En el ejemplo anterior, se reconoció que Tesla era un *** nombre propio ***. Aquí se requiere algún modelo estadístico. Por ejemplo, las palabras que siguen a \"the\" suelen ser sustantivos.\n",
    "\n",
    "Para obtener una lista completa de etiquetas POS, visite https://spacy.io/api/annotation#pos-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Dependencias\n",
    "También analizamos las dependencias sintácticas asignadas a cada token. `Tesla` se identifica como un` nsubj` o el *** sujeto nominal *** de la oración.\n",
    "\n",
    "Para obtener una lista completa de las dependencias sintácticas, visite https://spacy.io/api/annotation#dependency-parsing\n",
    "<br> Se puede encontrar una buena explicación de las dependencias escritas [aquí] (https://nlp.stanford.edu/software/dependencies_manual.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ver el nombre completo de una etiqueta, use `spacy.explain (tag)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Atributos de token adicionales\n",
    "Los veremos nuevamente en las próximas conferencias. Por ahora, solo queremos ilustrar parte de la otra información que spaCy asigna a los tokens:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Tag|Description|doc2[0].tag|\n",
    "|:------|:------:|:------|\n",
    "|`.text`|The original word text<!-- .element: style=\"text-align:left;\" -->|`Tesla`|\n",
    "|`.lemma_`|The base form of the word|`tesla`|\n",
    "|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|\n",
    "|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|\n",
    "|`.shape_`|The word shape – capitalization, punctuation, digits|`Xxxxx`|\n",
    "|`.is_alpha`|Is the token an alpha character?|`True`|\n",
    "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Spans\n",
    "Large Doc objects can be hard to work with at times. A **span** is a slice of Doc object in the form `Doc[start:stop]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En próximas conferencias veremos cómo crear objetos Span usando `Span ()`. Esto nos permitirá asignar información adicional al Span."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Sentences\n",
    "Certain tokens inside a Doc object may also receive a \"start of sentence\" tag. While this doesn't immediately build a list of sentences, these tags enable the generation of sentence segments through `Doc.sents`. Later we'll write our own segmentation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
