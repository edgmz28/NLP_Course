{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# Introducción: Librería NLTK\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procesamiento del lenguaje natural (PNL) a menudo se enseña a nivel académico desde la perspectiva de los lingüistas computacionales. Sin embargo, como científicos de datos, tenemos una visión más rica del mundo del lenguaje natural: datos no estructurados que, por su propia naturaleza, tienen información latente que es importante para los humanos. Los practicantes de PNL se han beneficiado de las técnicas de aprendizaje automático para desbloquear el significado de los grandes corpus, y en esta clase exploraremos cómo hacerlo en particular con Python y con Natural Language Toolkit (NLTK).\n",
    "\n",
    "NLTK es una excelente biblioteca para PNL basada en aprendizaje automático, escrita en Python por expertos tanto del mundo académico como de la industria. Python le permite crear aplicaciones de datos enriquecidos rápidamente, iterando sobre hipótesis. La combinación de Python + NLTK significa que puede agregar fácilmente productos de datos compatibles con el lenguaje a sus aplicaciones y flujos de trabajo analíticos más grandes.\n",
    "\n",
    "## Descripción rápida de NLTK\n",
    "NLTK son las siglas de Natural Language Toolkit y está escrito por dos eminentes lingüistas computacionales, Steven Bird (Investigador Asociado Senior de LDC y profesor de la Universidad de Melbourne) y Ewan Klein (Profesor de Lingüística en la Universidad de Edimburgo). NTLK proporciona una combinación de corpus de lenguaje natural, recursos léxicos y gramáticas de ejemplo con algoritmos, metodologías y demostraciones de procesamiento del lenguaje para una vista muy pitónica de \"baterías incluidas\" del procesamiento del lenguaje natural.\n",
    "\n",
    "Como tal, NLTK es perfecto para desarrollo e investigación. Su conjunto de bibliotecas incluye:\n",
    "\n",
    "- tokenización, derivación y etiquetado\n",
    "- fragmentación y análisis\n",
    "- modelado de lenguaje\n",
    "- clasificación y agrupamiento\n",
    "- semántica lógica\n",
    "\n",
    "NLTK es un recurso pedagógico útil para aprender NLP con Python y sirve como punto de partida para producir código de grado de producción que requiere análisis de lenguaje natural. También es importante comprender qué es NLTK _no_:\n",
    "\n",
    "- Producción lista para usar\n",
    "- ligero\n",
    "- Generalmente aplicable\n",
    "- Magia\n",
    "\n",
    "NLTK proporciona una variedad de herramientas que se pueden usar para explorar el dominio lingüístico, pero no es una dependencia liviana que se pueda incluir fácilmente en otros flujos de trabajo, especialmente aquellos que requieren pruebas unitarias e integrales u otros procesos de construcción. Esto se debe al hecho de que NLTK incluye una gran cantidad de código agregado, pero también una biblioteca rica y completa de corpus que alimentan los algoritmos incorporados.\n",
    "\n",
    "### Las partes buenas de NLTK\n",
    "\n",
    "- Preprocesamiento\n",
    "    - segmentation\n",
    "    - tokenization\n",
    "    - PoS tagging\n",
    "    \n",
    "- Procesamiento a nivel de palabras\n",
    "    - WordNet\n",
    "    - Lemmatization\n",
    "    - Stemming\n",
    "    - NGrams\n",
    "- Utilidades\n",
    "    - Tree\n",
    "    - FreqDist\n",
    "    - ConditionalFreqDist\n",
    "    - Streaming CorpusReaders\n",
    "- Clasificación\n",
    "    - Maximum Entropy\n",
    "    - Naive Bayes\n",
    "    - Decision Tree\n",
    "- Fragmentando\n",
    "- Named Entity Recognition\n",
    "- Parsers Galore!\n",
    "\n",
    "### Desventajas NLTK\n",
    "\n",
    "- Análisis sintáctico\n",
    "\n",
    "     - No incluye gramática (no es una caja negra)\n",
    "     - Sin análisis de funciones / dependencias\n",
    "     - No incluye gramática característica\n",
    "\n",
    "- El paquete sem\n",
    "    \n",
    "     - cálculo lambda y lógica de primer orden\n",
    "\n",
    "- Muchas cosas extra\n",
    "\n",
    "     - papers, programas de chat, alineaciones, etc.\n",
    "\n",
    "Conocer las partes buenas y malas lo ayudará a explorar NLTK más a fondo: buscar en el código fuente para extraer el material que necesita y luego mover ese código a producción. \n",
    "\n",
    "Exploraremos NLTK con más detalle \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Instalando NLTK\n",
    "\n",
    "Puede instalar NLTK de la siguiente manera:\n",
    "\n",
    "    ~$ pip install nltk\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para descargar los corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto abrirá una ventana con la que puede descargar los distintos corpus y modelos a una ubicación específica. Por ahora, continuemos y descárguemos todo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trabajando con un corpus de NLTK\n",
    "\n",
    "NLTK contiene una variedad de corpus, usemos algunos de ellos para trabajar un poco. Cargaremos el texto de _Moby Dick_ de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase `nltk.text.Text` es un envoltorio alrededor de una secuencia de tokens simples (cadenas) - destinada solo para _la exploración inicial de texto_ generalmente a través de Python REPL. Tiene los siguientes métodos:\n",
    "\n",
    "- common_contexts\n",
    "- concordance\n",
    "- collocations\n",
    "- count\n",
    "- plot\n",
    "- findall\n",
    "- index\n",
    "\n",
    "No debe usar esta clase en sistemas de nivel de producción, pero es útil para explorar fragmentos (pequeños) de texto de manera significativa.\n",
    "\n",
    "La función de concordancia realiza una búsqueda del token dado y luego también proporciona el contexto circundante:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado algún contexto que rodea una palabra, podemos descubrir palabras similares, p. Ej. palabras que aparecen con frecuencia en el mismo contexto y con una distribución similar: Similitud de distribución:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puede ver, esto toma un poco de tiempo, una de las razones por las que no se sugiere usar esta clase en el código de producción. Ahora que podemos hacer búsquedas y similitudes, encuentre los contextos comunes de un conjunto de palabras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "NLTK también usa matplotlib y pylab para mostrar gráficos y tablas que pueden mostrar dispersiones y frecuencia. Esto es especialmente interesante para el corpus de discursos innagurales dados por los presidentes de Estados Unidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para explorar gran parte del corpus integrado, utilice los siguientes métodos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos corpus exportan varios métodos vitales:\n",
    "\n",
    "- paras (iterate through each paragraph)\n",
    "- sents (iterate through each sentence)\n",
    "- words (iterate through each word)\n",
    "- raw   (get access to the raw text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
