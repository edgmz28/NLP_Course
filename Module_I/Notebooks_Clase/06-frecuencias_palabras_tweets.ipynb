{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;;\" src='Figures/alinco.png' /></a>\n",
    "\n",
    "# Modulo I: Construyendo y visualizando frecuencias de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este apartado, nos centraremos en la funci√≥n auxiliar `build_freqs()` y en la visualizaci√≥n de un conjunto de datos introducido en ella. En nuestro objetivo de an√°lisis de sentimiento de tweets, esta funci√≥n construir√° un diccionario donde podemos buscar cu√°ntas veces aparece una palabra en las listas de tweets positivos o negativos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos importando las librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importaremos algunas funciones auxiliares que proporcionamos en el archivo utils.py:\n",
    "\n",
    "* `process_tweet()`: Limpia el texto, lo convierte en token en palabras separadas, elimina las palabras vac√≠as y convierte las palabras en ra√≠ces.\n",
    "* `build_freqs()`: Cuenta la frecuencia con la que una palabra del \"corpus\" (el conjunto completo de tweets) se asoci√≥ con una etiqueta positiva \"1\" o una etiqueta negativa \"0\". Luego construye el diccionario `freqs`, donde cada clave es una tupla` (palabra, etiqueta) `, y el valor es el recuento de su frecuencia dentro del corpus de tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar el conjunto de datos de muestra NLTK\n",
    "\n",
    "Utilizaremos la [base de datos de tweeter de NLTK](http://www.nltk.org/howto/twitter.html#Using-a-Tweet-Corpus)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, crearemos una matriz de etiquetas que coincida con los sentimientos de nuestros tweets. Este tipo de datos funciona de forma muy similar a una lista normal, pero est√° optimizado para c√°lculos y manipulaci√≥n. La matriz `labels` estar√° compuesta por 10000 elementos. Los primeros 5000 se llenar√°n con etiquetas \"1\" que denotan sentimientos positivos, y los siguientes 5000 ser√°n etiquetas \"0\" que denotan lo contrario. Podemos hacer esto f√°cilmente con una serie de operaciones proporcionadas por la biblioteca `numpy`:\n",
    "\n",
    "* `np.ones()` \n",
    "* `np.zeros()` \n",
    "* `np.append()` - concatena arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recordatorio de uso de dicionarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing values and lookup keys\n",
    "\n",
    "Performing dictionary lookups and retrieval are common tasks in NLP. There are two ways to do this: \n",
    "\n",
    "* Using square bracket notation: This form is allowed if the lookup key is in the dictionary. It produces an error otherwise.\n",
    "* Using the [get()](https://docs.python.org/3/library/stdtypes.html#dict.get) method: This allows us to set a default value if the dictionary key does not exist. \n",
    "\n",
    "Let us see these in action:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using a square bracket lookup, it is common to use an if-else block to check for containment first (with the keyword `in`) before getting the item. On the other hand, you can use the `.get()` method if you want to set a default value when the key is not found. Let's compare these in the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diccionario de frecuencia de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Echemos un vistazo a la funci√≥n **build_freqs()** en **utils.py**. Esta es la funci√≥n que crea el diccionario que contiene los recuentos de palabras de cada corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def build_freqs(tweets, ys):\n",
    "    \"\"\"Build frequencies.\n",
    "    Input:\n",
    "        tweets: a list of tweets\n",
    "        ys: an m x 1 array with the sentiment label of each tweet\n",
    "            (either 0 or 1)\n",
    "    Output:\n",
    "        freqs: a dictionary mapping each (word, sentiment) pair to its\n",
    "        frequency\n",
    "    \"\"\"\n",
    "    # Convert np array to list since zip needs an iterable.\n",
    "    # The squeeze is necessary or the list ends up with one element.\n",
    "    # Also note that this is just a NOP if ys is already a list.\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "\n",
    "    # Start with an empty dictionary and populate it by looping over all tweets\n",
    "    # and over all processed words in each tweet.\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(yslist, tweets):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1    \n",
    "    return freqs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se muestra arriba, cada clave es una tupla de 2 elementos que contiene un par \"(palabra, y)\". La \"palabra\" es un elemento en un tweet procesado, mientras que \"y\" es un n√∫mero entero que representa el corpus: \"1\" para los tweets positivos y \"0\" para los tweets negativos. El valor asociado con esta clave es el n√∫mero de veces que esa palabra aparece en el corpus especificado. Por ejemplo:\n",
    "\n",
    "```\n",
    "# \"folowfriday\" aparece 25 veces en los tweets positivos\n",
    "('sigue el viernes', 1.0): 25\n",
    "\n",
    "# \"shame\" aparece 19 veces en los tweets negativos\n",
    "('shame', 0.0): 19\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora es el momento de usar el diccionario devuelto por la funci√≥n `build_freqs()`. Primero, alimentemos nuestras listas de `tweets` y` etiquetas` y luego imprimamos un informe b√°sico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desafortunadamente, esto no ayuda mucho a comprender los datos. Ser√≠a mejor visualizar este resultado para obtener mejores conocimientos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de recuentos de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seleccionaremos un conjunto de palabras que nos gustar√≠a visualizar. Es mejor almacenar esta informaci√≥n temporal en una tabla que sea muy f√°cil de usar m√°s adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seleccione algunas palabras para que aparezcan en el informe. asumiremos que cada palabra es √∫nica (es decir, sin duplicados)\n",
    "\n",
    "keys = ['happi', 'merri', 'nice', 'good', 'bad', 'sad', 'mad', 'best', 'pretti',\n",
    "        '‚ù§', ':)', ':(', 'üòí', 'üò¨', 'üòÑ', 'üòç', '‚ôõ',\n",
    "        'song', 'idea', 'power', 'play', 'magnific']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego podemos usar un diagrama de dispersi√≥n para inspeccionar esta tabla visualmente. En lugar de graficar los conteos sin procesar, lo trazaremos en la escala logar√≠tmica para tener en cuenta las amplias discrepancias entre los conteos sin procesar (por ejemplo, `:)` tiene 3568 conteos en positivo mientras que solo 2 en negativo). La l√≠nea roja marca el l√≠mite entre las √°reas positivas y negativas. Las palabras cercanas a la l√≠nea roja se pueden clasificar como neutrales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este cuadro es sencillo de interpretar. Muestra que los emoticones `:)` y `: (` son muy importantes para el an√°lisis de sentimientos. Por lo tanto, ¬°no debemos permitir que los pasos de preprocesamiento eliminen estos s√≠mbolos!\n",
    "\n",
    "¬øQu√© pasa con el s√≠mbolo de la corona?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
